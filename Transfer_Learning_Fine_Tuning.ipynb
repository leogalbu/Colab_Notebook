{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOtbwESTp3Oq/oKPfSV/7U2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leogalbu/Colab_Notebook/blob/Image_Classification/Transfer_Learning_Fine_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning - Fine Tuning\n"
      ],
      "metadata": {
        "id": "itSh0yW5xc_A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions"
      ],
      "metadata": {
        "id": "a8kogl5axsOY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xrwwi0SqxU9x",
        "outputId": "cb49184a-f9ab-40c7-8e57-be78ee5d9771"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-05 08:35:59--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-09-05 08:36:00 (104 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Import helper functions\n",
        "from helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, walk_through_dir"
      ],
      "metadata": {
        "id": "2QZXmLYexnkZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Data\n",
        "\n",
        "Im going to use keras.applications for the models"
      ],
      "metadata": {
        "id": "FwB8HAany1R4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get 10 % of training data\\\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RURdCWkSyXsn",
        "outputId": "01dba068-d7b4-4483-c03b-8b9bd5826e37"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-05 08:38:25--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.4.128, 74.125.24.128, 172.217.194.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.4.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168546183 (161M) [application/zip]\n",
            "Saving to: ‘10_food_classes_10_percent.zip’\n",
            "\n",
            "10_food_classes_10_ 100%[===================>] 160.74M  33.7MB/s    in 4.8s    \n",
            "\n",
            "2022-09-05 08:38:31 (33.7 MB/s) - ‘10_food_classes_10_percent.zip’ saved [168546183/168546183]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unzip_data('10_food_classes_10_percent.zip')"
      ],
      "metadata": {
        "id": "AWQ6D9AxzHPm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "walk_through_dir('10_food_classes_10_percent')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxRJJNj0zVnd",
        "outputId": "795a98a4-cfed-4816-8625-3859581fd818"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 directories and 0 images in '10_food_classes_10_percent'.\n",
            "There are 10 directories and 0 images in '10_food_classes_10_percent/test'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/fried_rice'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ramen'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/steak'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_curry'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ice_cream'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/pizza'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_wings'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/sushi'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/grilled_salmon'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/hamburger'.\n",
            "There are 10 directories and 0 images in '10_food_classes_10_percent/train'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/fried_rice'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ramen'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/steak'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_curry'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ice_cream'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/pizza'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_wings'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/sushi'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/grilled_salmon'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/hamburger'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and test dir paths\n",
        "train_dir = '10_food_classes_10_percent/train'\n",
        "test_dir = '10_food_classes_10_percent/test'"
      ],
      "metadata": {
        "id": "3jXWXa9Hzj9Q"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "_8ARefIGzpy0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = (224,224)\n",
        "BATCH_SIZE = 32\n",
        "train_data_10_percent = tf.keras.preprocessing.image_dataset_from_directory(train_dir, image_size=IMG_SIZE, label_mode='categorical', batch_size=BATCH_SIZE)\n",
        "test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir, image_size=IMG_SIZE, label_mode='categorical', batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1TaTULZz34C",
        "outputId": "838fc3c5-5eac-448b-d435-17fad391f7c3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 750 files belonging to 10 classes.\n",
            "Found 2500 files belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#for images, labels in train_data_10_percent.take(1):\n",
        "  #print(images,labels)"
      ],
      "metadata": {
        "id": "-JuEFqi_1SLW"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the model using KERAS FUNCTIONAL API"
      ],
      "metadata": {
        "id": "-a-dgYGq_NU_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model 0: Transfer Learning model using Keras Functional API"
      ],
      "metadata": {
        "id": "_60hRxXP_ezw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Create the base model with tf.keras.applications\n",
        "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
        "\n",
        "# 2. Freeze the base model (the pre trained weights will be freezed)\n",
        "base_model.trainable = False\n",
        "\n",
        "# 3. Create the input\n",
        "inputs = tf.keras.layers.Input(shape=(224,224,3), name='input_layer')\n",
        "# 4. If using a model like ResNet50V2 need to normalize inputs (not on EfficientNet's beacause its already have a rescaling layer)\n",
        "# x = tf.keras.layers.exprimental.preprocessing.Rescaling(1./255)(inputs)\n",
        "\n",
        "# 5. Pass the inputs to the base model\n",
        "x = base_model(inputs)\n",
        "print(f\"Shape after passing input: {x.shape}\")\n",
        "\n",
        "# 6. Average Pool the outputs (aggreagte all the most important information)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D(name='global_average_layer')(x)\n",
        "print(f\"Shape after GlobalAveragePooling2D: {x.shape}\")\n",
        "\n",
        "# 7. Create the ouput activation layer\n",
        "outputs = tf.keras.layers.Dense(10, activation='softmax', name='output_layer')(x)\n",
        "\n",
        "# 8. Combine inputs with the ouputs\n",
        "model_0 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# 9. Compile the model\n",
        "model_0.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=tf.keras.optimizers.Adam())\n",
        "\n",
        "# 10. Fit the model\n",
        "history_0 = model_0.fit(train_data_10_percent, batch_size=BATCH_SIZE, epochs=5, steps_per_epoch=len(train_data_10_percent), validation_data=test_data, validation_steps=len(test_data), callbacks=[create_tensorboard_callback(dir_name=\"transfer_learning\", experiment_name=\"10_percent_feature_extraction\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfWDN_pz_L9j",
        "outputId": "e7945497-09eb-481e-fe6a-4e00c9bf7938"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape after passing input: (None, 7, 7, 1280)\n",
            "Shape after GlobalAveragePooling2D: (None, 1280)\n",
            "Saving TensorBoard log files to: transfer_learning/10_percent_feature_extraction/20220905-095006\n",
            "Epoch 1/5\n",
            "24/24 [==============================] - 14s 376ms/step - loss: 1.9223 - accuracy: 0.3787 - val_loss: 1.3896 - val_accuracy: 0.6860\n",
            "Epoch 2/5\n",
            "24/24 [==============================] - 8s 318ms/step - loss: 1.1615 - accuracy: 0.7440 - val_loss: 0.9467 - val_accuracy: 0.7960\n",
            "Epoch 3/5\n",
            "24/24 [==============================] - 9s 356ms/step - loss: 0.8430 - accuracy: 0.8093 - val_loss: 0.7639 - val_accuracy: 0.8280\n",
            "Epoch 4/5\n",
            "24/24 [==============================] - 8s 329ms/step - loss: 0.6948 - accuracy: 0.8320 - val_loss: 0.6737 - val_accuracy: 0.8372\n",
            "Epoch 5/5\n",
            "24/24 [==============================] - 9s 358ms/step - loss: 0.5943 - accuracy: 0.8613 - val_loss: 0.6161 - val_accuracy: 0.8408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evalute\n",
        "model_0.evaluate(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgepS1xdCTEb",
        "outputId": "ba1f0123-b061-4358-8d55-23481d98d5e2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 6s 76ms/step - loss: 0.6161 - accuracy: 0.8408\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6160797476768494, 0.8407999873161316]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the layers in our model\n",
        "for layer_number, layer in enumerate(base_model.layers):\n",
        "  print(layer_number, layer.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WlIPpADD0o8",
        "outputId": "7af050f9-131b-466a-bb9a-c86291111b00"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 input_4\n",
            "1 rescaling_3\n",
            "2 normalization_3\n",
            "3 stem_conv_pad\n",
            "4 stem_conv\n",
            "5 stem_bn\n",
            "6 stem_activation\n",
            "7 block1a_dwconv\n",
            "8 block1a_bn\n",
            "9 block1a_activation\n",
            "10 block1a_se_squeeze\n",
            "11 block1a_se_reshape\n",
            "12 block1a_se_reduce\n",
            "13 block1a_se_expand\n",
            "14 block1a_se_excite\n",
            "15 block1a_project_conv\n",
            "16 block1a_project_bn\n",
            "17 block2a_expand_conv\n",
            "18 block2a_expand_bn\n",
            "19 block2a_expand_activation\n",
            "20 block2a_dwconv_pad\n",
            "21 block2a_dwconv\n",
            "22 block2a_bn\n",
            "23 block2a_activation\n",
            "24 block2a_se_squeeze\n",
            "25 block2a_se_reshape\n",
            "26 block2a_se_reduce\n",
            "27 block2a_se_expand\n",
            "28 block2a_se_excite\n",
            "29 block2a_project_conv\n",
            "30 block2a_project_bn\n",
            "31 block2b_expand_conv\n",
            "32 block2b_expand_bn\n",
            "33 block2b_expand_activation\n",
            "34 block2b_dwconv\n",
            "35 block2b_bn\n",
            "36 block2b_activation\n",
            "37 block2b_se_squeeze\n",
            "38 block2b_se_reshape\n",
            "39 block2b_se_reduce\n",
            "40 block2b_se_expand\n",
            "41 block2b_se_excite\n",
            "42 block2b_project_conv\n",
            "43 block2b_project_bn\n",
            "44 block2b_drop\n",
            "45 block2b_add\n",
            "46 block3a_expand_conv\n",
            "47 block3a_expand_bn\n",
            "48 block3a_expand_activation\n",
            "49 block3a_dwconv_pad\n",
            "50 block3a_dwconv\n",
            "51 block3a_bn\n",
            "52 block3a_activation\n",
            "53 block3a_se_squeeze\n",
            "54 block3a_se_reshape\n",
            "55 block3a_se_reduce\n",
            "56 block3a_se_expand\n",
            "57 block3a_se_excite\n",
            "58 block3a_project_conv\n",
            "59 block3a_project_bn\n",
            "60 block3b_expand_conv\n",
            "61 block3b_expand_bn\n",
            "62 block3b_expand_activation\n",
            "63 block3b_dwconv\n",
            "64 block3b_bn\n",
            "65 block3b_activation\n",
            "66 block3b_se_squeeze\n",
            "67 block3b_se_reshape\n",
            "68 block3b_se_reduce\n",
            "69 block3b_se_expand\n",
            "70 block3b_se_excite\n",
            "71 block3b_project_conv\n",
            "72 block3b_project_bn\n",
            "73 block3b_drop\n",
            "74 block3b_add\n",
            "75 block4a_expand_conv\n",
            "76 block4a_expand_bn\n",
            "77 block4a_expand_activation\n",
            "78 block4a_dwconv_pad\n",
            "79 block4a_dwconv\n",
            "80 block4a_bn\n",
            "81 block4a_activation\n",
            "82 block4a_se_squeeze\n",
            "83 block4a_se_reshape\n",
            "84 block4a_se_reduce\n",
            "85 block4a_se_expand\n",
            "86 block4a_se_excite\n",
            "87 block4a_project_conv\n",
            "88 block4a_project_bn\n",
            "89 block4b_expand_conv\n",
            "90 block4b_expand_bn\n",
            "91 block4b_expand_activation\n",
            "92 block4b_dwconv\n",
            "93 block4b_bn\n",
            "94 block4b_activation\n",
            "95 block4b_se_squeeze\n",
            "96 block4b_se_reshape\n",
            "97 block4b_se_reduce\n",
            "98 block4b_se_expand\n",
            "99 block4b_se_excite\n",
            "100 block4b_project_conv\n",
            "101 block4b_project_bn\n",
            "102 block4b_drop\n",
            "103 block4b_add\n",
            "104 block4c_expand_conv\n",
            "105 block4c_expand_bn\n",
            "106 block4c_expand_activation\n",
            "107 block4c_dwconv\n",
            "108 block4c_bn\n",
            "109 block4c_activation\n",
            "110 block4c_se_squeeze\n",
            "111 block4c_se_reshape\n",
            "112 block4c_se_reduce\n",
            "113 block4c_se_expand\n",
            "114 block4c_se_excite\n",
            "115 block4c_project_conv\n",
            "116 block4c_project_bn\n",
            "117 block4c_drop\n",
            "118 block4c_add\n",
            "119 block5a_expand_conv\n",
            "120 block5a_expand_bn\n",
            "121 block5a_expand_activation\n",
            "122 block5a_dwconv\n",
            "123 block5a_bn\n",
            "124 block5a_activation\n",
            "125 block5a_se_squeeze\n",
            "126 block5a_se_reshape\n",
            "127 block5a_se_reduce\n",
            "128 block5a_se_expand\n",
            "129 block5a_se_excite\n",
            "130 block5a_project_conv\n",
            "131 block5a_project_bn\n",
            "132 block5b_expand_conv\n",
            "133 block5b_expand_bn\n",
            "134 block5b_expand_activation\n",
            "135 block5b_dwconv\n",
            "136 block5b_bn\n",
            "137 block5b_activation\n",
            "138 block5b_se_squeeze\n",
            "139 block5b_se_reshape\n",
            "140 block5b_se_reduce\n",
            "141 block5b_se_expand\n",
            "142 block5b_se_excite\n",
            "143 block5b_project_conv\n",
            "144 block5b_project_bn\n",
            "145 block5b_drop\n",
            "146 block5b_add\n",
            "147 block5c_expand_conv\n",
            "148 block5c_expand_bn\n",
            "149 block5c_expand_activation\n",
            "150 block5c_dwconv\n",
            "151 block5c_bn\n",
            "152 block5c_activation\n",
            "153 block5c_se_squeeze\n",
            "154 block5c_se_reshape\n",
            "155 block5c_se_reduce\n",
            "156 block5c_se_expand\n",
            "157 block5c_se_excite\n",
            "158 block5c_project_conv\n",
            "159 block5c_project_bn\n",
            "160 block5c_drop\n",
            "161 block5c_add\n",
            "162 block6a_expand_conv\n",
            "163 block6a_expand_bn\n",
            "164 block6a_expand_activation\n",
            "165 block6a_dwconv_pad\n",
            "166 block6a_dwconv\n",
            "167 block6a_bn\n",
            "168 block6a_activation\n",
            "169 block6a_se_squeeze\n",
            "170 block6a_se_reshape\n",
            "171 block6a_se_reduce\n",
            "172 block6a_se_expand\n",
            "173 block6a_se_excite\n",
            "174 block6a_project_conv\n",
            "175 block6a_project_bn\n",
            "176 block6b_expand_conv\n",
            "177 block6b_expand_bn\n",
            "178 block6b_expand_activation\n",
            "179 block6b_dwconv\n",
            "180 block6b_bn\n",
            "181 block6b_activation\n",
            "182 block6b_se_squeeze\n",
            "183 block6b_se_reshape\n",
            "184 block6b_se_reduce\n",
            "185 block6b_se_expand\n",
            "186 block6b_se_excite\n",
            "187 block6b_project_conv\n",
            "188 block6b_project_bn\n",
            "189 block6b_drop\n",
            "190 block6b_add\n",
            "191 block6c_expand_conv\n",
            "192 block6c_expand_bn\n",
            "193 block6c_expand_activation\n",
            "194 block6c_dwconv\n",
            "195 block6c_bn\n",
            "196 block6c_activation\n",
            "197 block6c_se_squeeze\n",
            "198 block6c_se_reshape\n",
            "199 block6c_se_reduce\n",
            "200 block6c_se_expand\n",
            "201 block6c_se_excite\n",
            "202 block6c_project_conv\n",
            "203 block6c_project_bn\n",
            "204 block6c_drop\n",
            "205 block6c_add\n",
            "206 block6d_expand_conv\n",
            "207 block6d_expand_bn\n",
            "208 block6d_expand_activation\n",
            "209 block6d_dwconv\n",
            "210 block6d_bn\n",
            "211 block6d_activation\n",
            "212 block6d_se_squeeze\n",
            "213 block6d_se_reshape\n",
            "214 block6d_se_reduce\n",
            "215 block6d_se_expand\n",
            "216 block6d_se_excite\n",
            "217 block6d_project_conv\n",
            "218 block6d_project_bn\n",
            "219 block6d_drop\n",
            "220 block6d_add\n",
            "221 block7a_expand_conv\n",
            "222 block7a_expand_bn\n",
            "223 block7a_expand_activation\n",
            "224 block7a_dwconv\n",
            "225 block7a_bn\n",
            "226 block7a_activation\n",
            "227 block7a_se_squeeze\n",
            "228 block7a_se_reshape\n",
            "229 block7a_se_reduce\n",
            "230 block7a_se_expand\n",
            "231 block7a_se_excite\n",
            "232 block7a_project_conv\n",
            "233 block7a_project_bn\n",
            "234 top_conv\n",
            "235 top_bn\n",
            "236 top_activation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yFxQ4ebFEB2B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}